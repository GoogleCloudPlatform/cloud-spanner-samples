{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7992c8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2025 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f03d4d",
   "metadata": {},
   "source": [
    "# Google Spanner\n",
    "> [Spanner](https://cloud.google.com/spanner) is a highly scalable database that combines unlimited scalability with relational semantics, such as secondary indexes, strong consistency, schemas, and SQL providing 99.999% availability in one easy solution.\n",
    "\n",
    "This notebook goes over how to chunk documents when using `Spanner` for vector search. We'll use the `SpannerVectorStore` class from LangChain library.\n",
    "\n",
    "Learn more about Spanner's integration with LangChain by visiting the [GitHub repo](https://github.com/googleapis/langchain-google-spanner-python/).\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/GoogleCloudPlatform/spanner-vector-hybrid-search-samples/blob/main/chunking/chunking-basics.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04be520",
   "metadata": {},
   "source": [
    "## Before You Begin\n",
    "\n",
    "To run this notebook, you will need to do the following:\n",
    "\n",
    " * [Create a Google Cloud Project](https://developers.google.com/workspace/guides/create-project)\n",
    " * [Enable the Cloud Spanner API](https://console.cloud.google.com/flows/enableapi?apiid=spanner.googleapis.com)\n",
    " * [Create a Spanner instance](https://cloud.google.com/spanner/docs/create-manage-instances)\n",
    " * [Create a Spanner database](https://cloud.google.com/spanner/docs/create-manage-databases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7c81ae",
   "metadata": {},
   "source": [
    "### ü¶úüîó Install dependencies\n",
    "Let's first install langchain and Vertex AI libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4217f3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet langchain-text-splitters langchain-google-spanner langchain-google-vertexai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee926a17",
   "metadata": {},
   "source": [
    "**Colab only:** Uncomment the following cell to restart the kernel or use the button to restart the kernel. For Vertex AI Workbench you can restart the terminal using the button on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc3067e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Automatically restart kernel after installs so that your environment can access the new packages\n",
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e240c631",
   "metadata": {},
   "source": [
    "### üîê Authentication\n",
    "Authenticate to Google Cloud as the IAM user logged into this notebook in order to access your Google Cloud Project.\n",
    "\n",
    "* If you are using Colab to run this notebook, use the cell below and continue.\n",
    "* If you are using Vertex AI Workbench, check out the setup instructions [here](https://github.com/GoogleCloudPlatform/generative-ai/tree/main/setup-env)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05b6c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import auth\n",
    "\n",
    "auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f16e938",
   "metadata": {},
   "source": [
    "### ‚òÅ Set Your Google Cloud Project\n",
    "Set your Google Cloud project so that you can leverage Google Cloud resources within this notebook.\n",
    "\n",
    "If you don't know your project ID, try the following:\n",
    "\n",
    "* Run `gcloud config list`.\n",
    "* Run `gcloud projects list`.\n",
    "* See the support page: [Locate the project ID](https://support.google.com/googleapi/answer/7014113)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c91c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @markdown Please fill in the value below with your Google Cloud project ID and then run the cell.\n",
    "\n",
    "PROJECT_ID = \"<<your-gcp-project>>\"  # @param {type:\"string\"}\n",
    "\n",
    "# Set the project id\n",
    "!gcloud config set project {PROJECT_ID}\n",
    "%env GOOGLE_CLOUD_PROJECT={PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc93faf",
   "metadata": {},
   "source": [
    "### üí° API Enablement\n",
    "The `langchain-google-spanner` package requires that you [enable the Spanner API](https://console.cloud.google.com/flows/enableapi?apiid=spanner.googleapis.com) in your Google Cloud Project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f711392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable Spanner API\n",
    "!gcloud services enable spanner.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b954890e",
   "metadata": {},
   "source": [
    "### Set Spanner database values\n",
    "Find your database values, in the [Spanner Instances page](https://console.cloud.google.com/spanner?_ga=2.223735448.2062268965.1707700487-2088871159.1707257687)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6203a44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Set Your Values Here { display-mode: \"form\" }\n",
    "INSTANCE = \"<<your-spanner-instance>>\"  # @param {type: \"string\"}\n",
    "DATABASE = \"<<your-spanner-database>>\"  # @param {type: \"string\"}\n",
    "TABLE_NAME = \"<<your-spanner-table>>\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e666c7ac",
   "metadata": {},
   "source": [
    "# Setup some helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08fe6d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import spanner\n",
    "from google.cloud.spanner_admin_database_v1.types import spanner_database_admin\n",
    "\n",
    "spanner_client = spanner.Client()\n",
    "database_admin_api = spanner_client.database_admin_api\n",
    "\n",
    "OPERATION_TIMEOUT_SECONDS = 240\n",
    "\n",
    "def drop_table(table_name):\n",
    "    request = spanner_database_admin.UpdateDatabaseDdlRequest(\n",
    "        database=database_admin_api.database_path(\n",
    "            PROJECT_ID, INSTANCE, DATABASE\n",
    "        ),\n",
    "        statements=[\n",
    "            f\"DROP TABLE IF EXISTS {table_name}\"\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    operation = database_admin_api.update_database_ddl(request)\n",
    "\n",
    "    print(f\"Waiting for drop operation (on table '{table_name}') to complete...\")\n",
    "    operation.result(OPERATION_TIMEOUT_SECONDS)\n",
    "    print(f\"Dropped table {table_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf25543",
   "metadata": {},
   "source": [
    "### Initialize a table\n",
    "The `SpannerVectorStore` class instance requires a database table with id, content and embeddings columns. \n",
    "\n",
    "The helper method `init_vector_store_table()` that can be used to create a table with the proper schema for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89355fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for drop operation (on table 'vectors_search_data') to complete...\n",
      "Dropped table vectors_search_data\n",
      "Initializing vector store\n",
      "Waiting for operation to complete...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langchain_google_spanner\n",
    "\n",
    "from langchain_google_spanner import SecondaryIndex, SpannerVectorStore, TableColumn\n",
    "\n",
    "# Uncomment the following line to ensure that the table \n",
    "# where vector embeddings will be stored is dropped (if it exists).\n",
    "# This will clear out existing entries\n",
    "drop_table(TABLE_NAME)\n",
    "\n",
    "print(\"Initializing vector store\")\n",
    "SpannerVectorStore.init_vector_store_table(\n",
    "    instance_id=INSTANCE,\n",
    "    database_id=DATABASE,\n",
    "    table_name=TABLE_NAME,\n",
    "    # Customize the table creation\n",
    "    id_column=\"id\",\n",
    "    # content_column=\"content_column\",\n",
    "    # metadata_columns=[\n",
    "    #     TableColumn(name=\"metadata\", type=\"JSON\", is_null=True),\n",
    "    #     TableColumn(name=\"title\", type=\"STRING(MAX)\", is_null=False),\n",
    "    # ],\n",
    "    # secondary_indexes=[\n",
    "    #     SecondaryIndex(index_name=\"row_id_and_title\", columns=[\"row_id\", \"title\"])\n",
    "    # ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf8ef73",
   "metadata": {},
   "source": [
    "### Create an embedding class instance\n",
    "\n",
    "You can use any [LangChain embeddings model](https://python.langchain.com/docs/integrations/text_embedding/).\n",
    "You may need to enable Vertex AI API to use `VertexAIEmbeddings`. We recommend setting the embedding model's version for production, learn more about the [Text embeddings models](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/text-embeddings) and [Model versions](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/text-embeddings-api#model_versions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0cf610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable Vertex AI API\n",
    "!gcloud services enable aiplatform.googleapis.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ffb2fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "\n",
    "# Make sure you update the model version below reflect the latest production version\n",
    "embeddings = VertexAIEmbeddings(\n",
    "    model_name=\"text-embedding-005\", project=PROJECT_ID\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd4df7c",
   "metadata": {},
   "source": [
    "### Chunking overview\n",
    "With all of that setup out of the way, let's talk about chunking (aka text splitting). In order to index documents in a vector store like Spanner, it's necessary to first partition or chunk the document into smaller pieces and then send those pieces to the data store to be indexed.\n",
    "\n",
    "Why is it \"necessary\" to split documents before indexing them? At a high level, it's because documents (even small ones) are made up of a collection of smaller \"fragments\". You can think of these fragments as sentences, concepts, words, etc... And in fact, there are a variety of approaches for splitting documents, and LangChain offers multiple options as described [here](https://python.langchain.com/docs/concepts/text_splitters/#text-structured-based).\n",
    "\n",
    "As explained in the above LangChain article on text splitters, there are roughly four broad approaches for chunking:\n",
    "\n",
    "- Length based\n",
    "- Text-structure based\n",
    "- Document-structured based\n",
    "- Semantic meaning based"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da89971d",
   "metadata": {},
   "source": [
    "#### Chunking with CharacterTextSplitter followed by indexing on Spanner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1dc28c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "loader = TextLoader(\"vector_doc_input.txt\")\n",
    "file_contents = loader.load()\n",
    "\n",
    "# CharacterTextSplitter is just one of many text splitters\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "\n",
    "# Generate chunks (list of LangChain Documents)\n",
    "documents = text_splitter.split_documents(file_contents)\n",
    "\n",
    "ids = [str(uuid.uuid4()) for _ in range(len(documents))]\n",
    "# The following indexes the above chunks in Spanner\n",
    "vectorstore = SpannerVectorStore.from_documents(documents,\n",
    "                                                embeddings,\n",
    "                                                INSTANCE,\n",
    "                                                DATABASE,\n",
    "                                                TABLE_NAME,\n",
    "                                                id_column=\"id\",\n",
    "                                                ids=ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11df4eb2",
   "metadata": {},
   "source": [
    "The above code chunks the document and indexes the chunks in the specified Spanner table. Let's query the underlying Spanner table (TABLE_NAME) directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c74df7fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04b6d5ec-5f1a-45b5-96d3-bc8212bb60d1</td>\n",
       "      <td>Since both correctness and availability are cr...</td>\n",
       "      <td>[-0.024999909102916718, -0.001801451202481985,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>232c7770-9c71-4889-b5bc-03d6b5ea836b</td>\n",
       "      <td>Blackhole the request: Sometimes the file syst...</td>\n",
       "      <td>[-0.0427422858774662, -0.0013925273669883609, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50270e45-119b-479f-a4fa-6f57ec3ad8a5</td>\n",
       "      <td>Upping reliability with chaos testing\\nWe run ...</td>\n",
       "      <td>[-0.04426778107881546, 0.0026189256459474564, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5179e395-d7a9-4181-8b68-e6601a936e99</td>\n",
       "      <td>5. Cloud faults\\nAccess to Spanner from the Go...</td>\n",
       "      <td>[-0.04665933921933174, 0.001961533911526203, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>536e8982-4ed4-4ca7-a6a4-00ac9385d73b</td>\n",
       "      <td>A fault-tolerant design foundation\\nSpanner is...</td>\n",
       "      <td>[-0.04364815726876259, 0.007677283603698015, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>576eacb1-882f-43e3-b4cb-ced2bb33a0fe</td>\n",
       "      <td>Declared checks and foreign key constraints ar...</td>\n",
       "      <td>[-0.041425663977861404, -0.01261491421610117, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7b2dd05c-4d0b-4d0f-876d-3289bcd0ac8c</td>\n",
       "      <td>A read or query on the database does not retur...</td>\n",
       "      <td>[-0.018720634281635284, -0.020843015983700752,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8338f341-d542-4a4c-b817-5af2e7c74c20</td>\n",
       "      <td>Spanner earns its reputation for reliability\\n...</td>\n",
       "      <td>[-0.04425937682390213, -0.005921074189245701, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8ec74f92-bfb8-4226-b0ee-64dbbce50c89</td>\n",
       "      <td>The restart logic is quite complex and we even...</td>\n",
       "      <td>[-0.028140805661678314, -0.019556596875190735,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ab7ba4fc-fce5-4260-8ddb-047b666b7582</td>\n",
       "      <td>For example, through chaos testing, we found a...</td>\n",
       "      <td>[-0.029230546206235886, -0.012972258031368256,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  04b6d5ec-5f1a-45b5-96d3-bc8212bb60d1   \n",
       "1  232c7770-9c71-4889-b5bc-03d6b5ea836b   \n",
       "2  50270e45-119b-479f-a4fa-6f57ec3ad8a5   \n",
       "3  5179e395-d7a9-4181-8b68-e6601a936e99   \n",
       "4  536e8982-4ed4-4ca7-a6a4-00ac9385d73b   \n",
       "5  576eacb1-882f-43e3-b4cb-ced2bb33a0fe   \n",
       "6  7b2dd05c-4d0b-4d0f-876d-3289bcd0ac8c   \n",
       "7  8338f341-d542-4a4c-b817-5af2e7c74c20   \n",
       "8  8ec74f92-bfb8-4226-b0ee-64dbbce50c89   \n",
       "9  ab7ba4fc-fce5-4260-8ddb-047b666b7582   \n",
       "\n",
       "                                             content  \\\n",
       "0  Since both correctness and availability are cr...   \n",
       "1  Blackhole the request: Sometimes the file syst...   \n",
       "2  Upping reliability with chaos testing\\nWe run ...   \n",
       "3  5. Cloud faults\\nAccess to Spanner from the Go...   \n",
       "4  A fault-tolerant design foundation\\nSpanner is...   \n",
       "5  Declared checks and foreign key constraints ar...   \n",
       "6  A read or query on the database does not retur...   \n",
       "7  Spanner earns its reputation for reliability\\n...   \n",
       "8  The restart logic is quite complex and we even...   \n",
       "9  For example, through chaos testing, we found a...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-0.024999909102916718, -0.001801451202481985,...  \n",
       "1  [-0.0427422858774662, -0.0013925273669883609, ...  \n",
       "2  [-0.04426778107881546, 0.0026189256459474564, ...  \n",
       "3  [-0.04665933921933174, 0.001961533911526203, 0...  \n",
       "4  [-0.04364815726876259, 0.007677283603698015, 0...  \n",
       "5  [-0.041425663977861404, -0.01261491421610117, ...  \n",
       "6  [-0.018720634281635284, -0.020843015983700752,...  \n",
       "7  [-0.04425937682390213, -0.005921074189245701, ...  \n",
       "8  [-0.028140805661678314, -0.019556596875190735,...  \n",
       "9  [-0.029230546206235886, -0.012972258031368256,...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from google.cloud import spanner\n",
    "\n",
    "spanner_db = spanner.Client(project=PROJECT_ID).instance(INSTANCE).database(DATABASE)\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "with spanner_db.snapshot() as snapshot:\n",
    "    results = snapshot.execute_sql(f\"SELECT * FROM {TABLE_NAME} LIMIT 10;\")\n",
    "\n",
    "    rows = []\n",
    "    for row in results:\n",
    "        rows.append(row)\n",
    "    \n",
    "    # Get column names\n",
    "    cols = [x.name for x in results.fields]\n",
    "\n",
    "    # Convert to pandas dataframe\n",
    "    result_df = pd.DataFrame(rows, columns = cols)\n",
    "\n",
    "display(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16a348b",
   "metadata": {},
   "source": [
    "Let's now do a similarity search on the indexed data via LangChain and display the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1a9bd93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num results: 3\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spanner earns its reputation for reliability\\nSpanner is fault tolerant by design. We continuously validate Spanner‚Äôs reliability by running many large-scale randomized system tests that employ chaos testing.\\n\\nYou can learn more about what makes Spanner unique and how it‚Äôs being used today. Or try it yourself for free for 90-days or for as little as $65 USD/month for a production-ready instance that grows with your business without downtime or disruptive re-architecture.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5. Cloud faults\\nAccess to Spanner from the Google Cloud Platform is mediated by Spanner API Front End Servers, which proxy requests coming into Google Cloud through Google front ends to a Spanner database. External clients open sessions with the Spanner database and execute transactions on these sessions. For Spanner, we crash the Spanner API frontend servers, which forces sessions to migrate to other Spanner API frontend servers. This should not be visible to the client (besides some additional latency).\\n\\n6. Regional outages\\nThe largest faults we simulate in system tests are outages of an entire region, forcing Spanner to serve data from a quorum of other regions. The majority of our system tests simulate several kinds of regional outages, triggered either by file system or network outages, and we verify Spanner continues to serve. This resilience is a property of the Paxos algorithm, which guarantees progress as long as a quorum (2 of 3, or 3 of 5) of replicas remain healthy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A fault-tolerant design foundation\\nSpanner is built from ‚Äúmostly reliable‚Äù components including machines, disks, and networking hardware that have a low rate of failure. Even so, bad things happen: bad memory and disks may lead to data corruption; file accesses may yield transient or permanent errors or corruption; or network connectivity within or between data centers may be throttled or lost altogether. Worst of all, software bugs sometimes produce correlated failures in all servers running the same version of the code.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           page_content\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Spanner earns its reputation for reliability\\nSpanner is fault tolerant by design. We continuously validate Spanner‚Äôs reliability by running many large-scale randomized system tests that employ chaos testing.\\n\\nYou can learn more about what makes Spanner unique and how it‚Äôs being used today. Or try it yourself for free for 90-days or for as little as $65 USD/month for a production-ready instance that grows with your business without downtime or disruptive re-architecture.\n",
       "1  5. Cloud faults\\nAccess to Spanner from the Google Cloud Platform is mediated by Spanner API Front End Servers, which proxy requests coming into Google Cloud through Google front ends to a Spanner database. External clients open sessions with the Spanner database and execute transactions on these sessions. For Spanner, we crash the Spanner API frontend servers, which forces sessions to migrate to other Spanner API frontend servers. This should not be visible to the client (besides some additional latency).\\n\\n6. Regional outages\\nThe largest faults we simulate in system tests are outages of an entire region, forcing Spanner to serve data from a quorum of other regions. The majority of our system tests simulate several kinds of regional outages, triggered either by file system or network outages, and we verify Spanner continues to serve. This resilience is a property of the Paxos algorithm, which guarantees progress as long as a quorum (2 of 3, or 3 of 5) of replicas remain healthy.\n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      A fault-tolerant design foundation\\nSpanner is built from ‚Äúmostly reliable‚Äù components including machines, disks, and networking hardware that have a low rate of failure. Even so, bad things happen: bad memory and disks may lead to data corruption; file accesses may yield transient or permanent errors or corruption; or network connectivity within or between data centers may be throttled or lost altogether. Worst of all, software bugs sometimes produce correlated failures in all servers running the same version of the code."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = vectorstore.similarity_search(query=\"resilience\", k=3)\n",
    "print('Num results: ' + str(len(results)))\n",
    "print()\n",
    "\n",
    "search_rows = [x.page_content for x in results]\n",
    "cols = ['page_content']\n",
    "\n",
    "# The following ensures that the full chunked text fragment is displayed without truncation\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "search_df = pd.DataFrame(search_rows, columns = cols)\n",
    "display(search_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3398773",
   "metadata": {},
   "source": [
    "The above chunking approach \"blindly\" breaks up our input document into 1000 character chunks - without regard for the semantic meaning contained in these chunks. Let's use a more sophisticated chunking approach provided by LangChain: SemanticChunker. More info [here](https://python.langchain.com/docs/how_to/semantic-chunker/). First, let's initialize a separate Spanner table to index embeddings from this new chunking approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dafe3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for drop operation (on table 'vectors_search_data_sc') to complete...\n",
      "Dropped table vectors_search_data_sc\n",
      "Waiting for operation to complete...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "\n",
    "# A separate table to index using second chunking approach\n",
    "TABLE_NAME_SC = \"<<your-spanner-table-sc>>\" # sc for semantic chunking\n",
    "\n",
    "drop_table(TABLE_NAME_SC)\n",
    "SpannerVectorStore.init_vector_store_table(\n",
    "    instance_id=INSTANCE,\n",
    "    database_id=DATABASE,\n",
    "    table_name=TABLE_NAME_SC,\n",
    "    # Customize the table creation\n",
    "    id_column=\"id\",\n",
    "    # content_column=\"content_column\",\n",
    "    # metadata_columns=[\n",
    "    #     TableColumn(name=\"metadata\", type=\"JSON\", is_null=True),\n",
    "    #     TableColumn(name=\"title\", type=\"STRING(MAX)\", is_null=False),\n",
    "    # ],\n",
    "    # secondary_indexes=[\n",
    "    #     SecondaryIndex(index_name=\"row_id_and_title\", columns=[\"row_id\", \"title\"])\n",
    "    # ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8838f1d",
   "metadata": {},
   "source": [
    "Let's now index the chunks into the new table that we just initialized above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47757ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use SemanticChunker this time\n",
    "text_splitter = SemanticChunker(embeddings)\n",
    "\n",
    "documents = []\n",
    "\n",
    "with open(\"vector_doc_input.txt\") as f:\n",
    "    doc_contents = f.read()\n",
    "    # Generate chunks (list of LangChain Documents)\n",
    "    documents = text_splitter.create_documents([doc_contents])\n",
    "\n",
    "ids = [str(uuid.uuid4()) for _ in range(len(documents))]\n",
    "\n",
    "# The following indexes the above chunks in Spanner\n",
    "vectorstore_sc = SpannerVectorStore.from_documents(documents,\n",
    "                                                embeddings,\n",
    "                                                INSTANCE,\n",
    "                                                DATABASE,\n",
    "                                                TABLE_NAME_SC,\n",
    "                                                id_column=\"id\",\n",
    "                                                ids=ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e85215",
   "metadata": {},
   "source": [
    "Let's do a search using these newly indexed (using the SemanticChunker) documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7a1612e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num results: 3\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5. Cloud faults\\nAccess to Spanner from the Google Cloud Platform is mediated by Spanner API Front End Servers, which proxy requests coming into Google Cloud through Google front ends to a Spanner database. External clients open sessions with the Spanner database and execute transactions on these sessions. For Spanner, we crash the Spanner API frontend servers, which forces sessions to migrate to other Spanner API frontend servers. This should not be visible to the client (besides some additional latency). 6. Regional outages\\nThe largest faults we simulate in system tests are outages of an entire region, forcing Spanner to serve data from a quorum of other regions. The majority of our system tests simulate several kinds of regional outages, triggered either by file system or network outages, and we verify Spanner continues to serve. This resilience is a property of the Paxos algorithm, which guarantees progress as long as a quorum (2 of 3, or 3 of 5) of replicas remain healthy. Spanner earns its reputation for reliability\\nSpanner is fault tolerant by design. We continuously validate Spanner‚Äôs reliability by running many large-scale randomized system tests that employ chaos testing. You can learn more about what makes Spanner unique and how it‚Äôs being used today. Or try it yourself for free for 90-days or for as little as $65 USD/month for a production-ready instance that grows with your business without downtime or disruptive re-architecture.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SOURCE: https://cloud.google.com/blog/products/databases/chaos-testing-spanner-improves-reiliability\\n\\nOne of the secrets behind Spanner‚Äôs reliability is the team‚Äôs extensive use of chaos testing, the process of deliberately injecting faults into production-like instances of the database. Although engineers focus on testing the ‚Äúhappy path,‚Äù most software bugs occur when things go wrong. Given Spanner‚Äôs complex architecture and constantly evolving codebase, it is inevitable that bugs will be introduced. Here, we give an overview of the types of chaos testing we employ and the kinds of bugs it finds. A fault-tolerant design foundation\\nSpanner is built from ‚Äúmostly reliable‚Äù components including machines, disks, and networking hardware that have a low rate of failure. Even so, bad things happen: bad memory and disks may lead to data corruption; file accesses may yield transient or permanent errors or corruption; or network connectivity within or between data centers may be throttled or lost altogether. Worst of all, software bugs sometimes produce correlated failures in all servers running the same version of the code. Since both correctness and availability are critical, Spanner uses principles of fault-tolerant design to mask failures of these components and achieve high reliability for the service. For example, checksums are used to detect data corruption at many levels. Spanner tablets, which store a fragment of the database, are replicated across three or (usually) more data centers and the reads and writes use Paxos to achieve consensus and consistency of the distributed state. Checksums are also used to detect corruption of a tablet replica.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The data for these tablets is stored in files, and the file system keeps multiple copies of the data blocks within the data center, using checksums to detect corrupted blocks. Finally, we proceed cautiously when rolling out new software versions, alerting on any anomalies that may be caused by a new bug. Upping reliability with chaos testing\\nWe run over a thousand system tests per week to validate that Spanner‚Äôs design and implementation actually mask faults and provide a highly reliable service. Each test creates a production-like instance of Spanner comprising hundreds of processes running on the same computing platform and using the same dependent systems (e.g., file system, lock service) as production Spanner. Most tests run for between one and 24 hours and execute tens or hundreds of thousands of transactions. Actual faults in production occur at a very low rate. To cover Spanner‚Äôs error-handling and fault-tolerance mechanisms, we inject faults (e.g., file and network errors) at a much higher rate in these system tests. If these faults uncover bugs, the test fails in one of several ways:\\n\\nA read or query on the database does not return the expected result. Being able to compute the expected result of a randomly generated read/query on a database populated with randomly generated data is a challenging problem. Spanner‚Äôs strong consistency model is the key to validate read/query results efficiently: each transaction records a log summarizing its effects, and subsequent transactions can replay these logs to compute the state they should observe. We describe this in further detail in an earlier article. A Spanner API call returns an unexpected error. A Spanner server crashes in an unexpected way. Some of the faults we inject will cause a server to crash, but we filter these and fail the test only if some new unexpected crash occurs. One of Spanner‚Äôs internal consistency checkers reports a problem. Checkers verify that:\\n\\nFiles are not leaked (like Unix fsck, but on the distributed file system)\\n\\nSecondary indexes are consistent with the tables they index\\n\\nDeclared checks and foreign key constraints are satisfied\\n\\nAll replicas of a tablet are equal\\n\\nLet‚Äôs take a look at the kinds of faults that we inject when chaos testing Spanner. 1. Server crashes\\nOne of the most basic faults we inject is to force a server to crash abruptly (e.g., via a SIGABRT Unix signal). This simple fault causes lots of complex failure recovery logic to be executed:\\n\\nServers use a disk-based log to protect against the loss of their in-memory state, thus crashing exercises the logic that recovers the state of all the tablets that were on the crashed server from their logs. All distributed transactions being coordinated by the crashed server must abort and be restarted since the locks are kept in memory. Clients that were pulling data from the crashed server via reads and/or queries are forced to fail over to another replica. The client must resume the operation without starting again at the beginning, and without losing or duplicating any results. The restart logic is quite complex and we even trigger restarts without server crashes to exercise it at various points in the streaming of the results.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                page_content\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               5. Cloud faults\\nAccess to Spanner from the Google Cloud Platform is mediated by Spanner API Front End Servers, which proxy requests coming into Google Cloud through Google front ends to a Spanner database. External clients open sessions with the Spanner database and execute transactions on these sessions. For Spanner, we crash the Spanner API frontend servers, which forces sessions to migrate to other Spanner API frontend servers. This should not be visible to the client (besides some additional latency). 6. Regional outages\\nThe largest faults we simulate in system tests are outages of an entire region, forcing Spanner to serve data from a quorum of other regions. The majority of our system tests simulate several kinds of regional outages, triggered either by file system or network outages, and we verify Spanner continues to serve. This resilience is a property of the Paxos algorithm, which guarantees progress as long as a quorum (2 of 3, or 3 of 5) of replicas remain healthy. Spanner earns its reputation for reliability\\nSpanner is fault tolerant by design. We continuously validate Spanner‚Äôs reliability by running many large-scale randomized system tests that employ chaos testing. You can learn more about what makes Spanner unique and how it‚Äôs being used today. Or try it yourself for free for 90-days or for as little as $65 USD/month for a production-ready instance that grows with your business without downtime or disruptive re-architecture.\n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               SOURCE: https://cloud.google.com/blog/products/databases/chaos-testing-spanner-improves-reiliability\\n\\nOne of the secrets behind Spanner‚Äôs reliability is the team‚Äôs extensive use of chaos testing, the process of deliberately injecting faults into production-like instances of the database. Although engineers focus on testing the ‚Äúhappy path,‚Äù most software bugs occur when things go wrong. Given Spanner‚Äôs complex architecture and constantly evolving codebase, it is inevitable that bugs will be introduced. Here, we give an overview of the types of chaos testing we employ and the kinds of bugs it finds. A fault-tolerant design foundation\\nSpanner is built from ‚Äúmostly reliable‚Äù components including machines, disks, and networking hardware that have a low rate of failure. Even so, bad things happen: bad memory and disks may lead to data corruption; file accesses may yield transient or permanent errors or corruption; or network connectivity within or between data centers may be throttled or lost altogether. Worst of all, software bugs sometimes produce correlated failures in all servers running the same version of the code. Since both correctness and availability are critical, Spanner uses principles of fault-tolerant design to mask failures of these components and achieve high reliability for the service. For example, checksums are used to detect data corruption at many levels. Spanner tablets, which store a fragment of the database, are replicated across three or (usually) more data centers and the reads and writes use Paxos to achieve consensus and consistency of the distributed state. Checksums are also used to detect corruption of a tablet replica.\n",
       "2  The data for these tablets is stored in files, and the file system keeps multiple copies of the data blocks within the data center, using checksums to detect corrupted blocks. Finally, we proceed cautiously when rolling out new software versions, alerting on any anomalies that may be caused by a new bug. Upping reliability with chaos testing\\nWe run over a thousand system tests per week to validate that Spanner‚Äôs design and implementation actually mask faults and provide a highly reliable service. Each test creates a production-like instance of Spanner comprising hundreds of processes running on the same computing platform and using the same dependent systems (e.g., file system, lock service) as production Spanner. Most tests run for between one and 24 hours and execute tens or hundreds of thousands of transactions. Actual faults in production occur at a very low rate. To cover Spanner‚Äôs error-handling and fault-tolerance mechanisms, we inject faults (e.g., file and network errors) at a much higher rate in these system tests. If these faults uncover bugs, the test fails in one of several ways:\\n\\nA read or query on the database does not return the expected result. Being able to compute the expected result of a randomly generated read/query on a database populated with randomly generated data is a challenging problem. Spanner‚Äôs strong consistency model is the key to validate read/query results efficiently: each transaction records a log summarizing its effects, and subsequent transactions can replay these logs to compute the state they should observe. We describe this in further detail in an earlier article. A Spanner API call returns an unexpected error. A Spanner server crashes in an unexpected way. Some of the faults we inject will cause a server to crash, but we filter these and fail the test only if some new unexpected crash occurs. One of Spanner‚Äôs internal consistency checkers reports a problem. Checkers verify that:\\n\\nFiles are not leaked (like Unix fsck, but on the distributed file system)\\n\\nSecondary indexes are consistent with the tables they index\\n\\nDeclared checks and foreign key constraints are satisfied\\n\\nAll replicas of a tablet are equal\\n\\nLet‚Äôs take a look at the kinds of faults that we inject when chaos testing Spanner. 1. Server crashes\\nOne of the most basic faults we inject is to force a server to crash abruptly (e.g., via a SIGABRT Unix signal). This simple fault causes lots of complex failure recovery logic to be executed:\\n\\nServers use a disk-based log to protect against the loss of their in-memory state, thus crashing exercises the logic that recovers the state of all the tablets that were on the crashed server from their logs. All distributed transactions being coordinated by the crashed server must abort and be restarted since the locks are kept in memory. Clients that were pulling data from the crashed server via reads and/or queries are forced to fail over to another replica. The client must resume the operation without starting again at the beginning, and without losing or duplicating any results. The restart logic is quite complex and we even trigger restarts without server crashes to exercise it at various points in the streaming of the results."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_sc = vectorstore_sc.similarity_search(query=\"resilience\", k=3)\n",
    "print('Num results: ' + str(len(results_sc)))\n",
    "print()\n",
    "\n",
    "search_rows_sc = [x.page_content for x in results_sc]\n",
    "\n",
    "# The following ensures that the full chunked text fragment is displayed without truncation\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "cols = ['page_content']\n",
    "search_sc_df = pd.DataFrame(search_rows_sc, columns = cols)\n",
    "display(search_sc_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e591b5f6",
   "metadata": {},
   "source": [
    "As you can see, these results are more self-consistent. To drive the point home further, let's see how these two chunking approaches fare when they're used in a RAG workflow.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5635ca81",
   "metadata": {},
   "source": [
    "## Setup for RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ead7722",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import ChatVertexAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# this vector store uses the embeddings generated\n",
    "# with CharacterTextSplitter\n",
    "vector_store = SpannerVectorStore(\n",
    "    embedding_service=embeddings,\n",
    "    instance_id=INSTANCE,\n",
    "    database_id=DATABASE,\n",
    "    table_name=TABLE_NAME,\n",
    "    id_column=\"id\",\n",
    "    content_column=\"content\",\n",
    "    embedding_column=\"embedding\",\n",
    ")\n",
    "\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"mmr\", search_kwargs={\"k\": 5, \"lambda_mult\": 0.8}\n",
    ")\n",
    "\n",
    "# this vector store uses the embeddings generated\n",
    "# with SemanticChunker\n",
    "vector_store_sc = SpannerVectorStore(\n",
    "    embedding_service=embeddings,\n",
    "    instance_id=INSTANCE,\n",
    "    database_id=DATABASE,\n",
    "    table_name=TABLE_NAME_SC,\n",
    "    id_column=\"id\",\n",
    "    content_column=\"content\",\n",
    "    embedding_column=\"embedding\",\n",
    ")\n",
    "\n",
    "retriever_sc = vector_store_sc.as_retriever(\n",
    "    search_type=\"mmr\", search_kwargs={\"k\": 5, \"lambda_mult\": 0.8}\n",
    ")\n",
    "\n",
    "# let's initialize our llm\n",
    "llm = ChatVertexAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    max_retries=6,\n",
    "    stop=None,\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "prompt_str = \"\"\"You are a knowledgeable and helpful bot who answers questions for a \n",
    "                technical audience at a 200 level of complexity. Please ensure that your\n",
    "                responses are self-consistent. With that background, please answer this \n",
    "                question: {question} based on the following context: {context}\"\"\"\n",
    "prompt_template = PromptTemplate.from_template(prompt_str)\n",
    "\n",
    "# helper method to format fragments\n",
    "# retrieved from vector store\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9866942",
   "metadata": {},
   "source": [
    "First, let's run a RAG using context on the CharacterTextSplitter based chunking approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373f02fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spanner uses chaos testing to increase availability by proactively injecting faults into production-like instances. This allows engineers to validate Spanner's fault-tolerance mechanisms and error-handling code. By injecting faults such as server crashes, network partitions, and errors in dependent systems, Spanner can identify and fix bugs that would otherwise occur in production. This helps to ensure that Spanner can continue to operate even when failures occur, thus increasing availability.\n",
      "\n",
      "Here's a breakdown of how specific fault injections contribute to increased availability:\n",
      "\n",
      "*   **Server Crashes:** Simulating server crashes validates the recovery mechanisms for in-memory state from disk-based logs, ensures distributed transactions abort and restart correctly, and verifies that clients can failover to other replicas without data loss or duplication. This ensures that the service remains available even if individual servers fail.\n",
      "\n",
      "*   **Network Partitions:** Blocking RPCs to specific data centers simulates network partitions, ensuring that clients can failover to healthy replicas in other data centers. This maintains availability even when network connectivity is disrupted.\n",
      "\n",
      "*   **Dependent System Errors:** Blocking or erroring RPCs to dependent systems, like the key service for data encryption, tests the system's ability to handle failures in external services. This ensures that Spanner can continue to operate, possibly in a degraded mode, even when dependent services are unavailable.\n",
      "\n",
      "*   **Network Throttling:** Dropping RPCs with specific network priorities simulates network throttling, ensuring that critical RPCs are prioritized and that the system remains responsive even under heavy load. This helps maintain availability by ensuring that essential operations can still complete.\n",
      "\n",
      "By continuously running these chaos tests, Spanner can identify and address potential failure points, ultimately leading to a more robust and highly available database service.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import textwrap\n",
    "\n",
    "# notice that we're passing in the retriever\n",
    "# that was instantiated on top of the table\n",
    "# containing \"chunks\" generated via CharacterTextSplitter\n",
    "rag_chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt_template\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    ")\n",
    "\n",
    "ai_response = rag_chain.invoke(\"How does Spanner increase availability with chaos testing?\")\n",
    "# ai_response = wrapped_text = textwrap.fill(ai_response, width=80)\n",
    "\n",
    "print(ai_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d4b243",
   "metadata": {},
   "source": [
    "Now let's run a RAG using the table (vector store) containing chunks generated by the SemanticChunker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ea137ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spanner uses chaos testing to increase availability by proactively injecting faults into production-like instances of the database. This allows engineers to validate that Spanner's fault-tolerant design and implementation effectively mask failures and maintain a highly reliable service. Here's how:\n",
      "\n",
      "*   **Fault Injection:** Spanner injects various faults, such as server crashes, file system errors (e.g., corruption, blackholes), RPC failures (delays, errors, network partitions), memory/quota exhaustion, cloud frontend server crashes and regional outages.\n",
      "*   **Testing Recovery Mechanisms:** By injecting these faults, Spanner tests its recovery mechanisms, including:\n",
      "    *   **Server crash recovery:** Validates the disk-based log recovery mechanism, distributed transaction abort/restart logic, and client failover to other replicas.\n",
      "    *   **File system fault tolerance:** Ensures that Spanner can handle file system errors, data corruption (detected by checksums), and file system unavailability by failing over to alternate replicas in different data centers.\n",
      "    *   **RPC fault tolerance:** Verifies that Spanner can handle RPC delays, errors, and network partitions by retrying requests, failing over to other replicas, and prioritizing critical RPCs.\n",
      "    *   **Memory/quota management:** Tests the pushback mechanism when servers run low on memory and ensures that quota exceeded errors are handled correctly.\n",
      "    *   **Cloud frontend server crashes:** Validates that client sessions can migrate to other frontend servers without disruption.\n",
      "    *   **Regional outages:** Confirms that Spanner can continue serving data from a quorum of other regions, leveraging the Paxos algorithm for resilience.\n",
      "*   **Validating Expected Behavior:** The tests validate that Spanner behaves as expected in the presence of faults, including:\n",
      "    *   Returning the correct results for reads and queries.\n",
      "    *   Returning expected errors for API calls.\n",
      "    *   Avoiding unexpected server crashes.\n",
      "    *   Maintaining internal consistency (e.g., no file leaks, consistent secondary indexes, satisfied constraints, equal tablet replicas).\n",
      "*   **Identifying and Fixing Bugs:** Chaos testing helps uncover bugs in Spanner's error-handling and fault-tolerance mechanisms, preventing them from reaching production. For example, a test injecting a rare Colossus error code revealed a data loss bug in the tablet compaction code.\n",
      "\n",
      "By continuously running these chaos tests, Spanner validates its ability to mask faults and maintain high availability, even in the face of unexpected failures.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# notice that we're passing in the retriever\n",
    "# that was instantiated on top of the table\n",
    "# containing \"chunks\" generated via SemanticChunker\n",
    "rag_chain = (\n",
    "        {\"context\": retriever_sc | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt_template\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    ")\n",
    "\n",
    "ai_response = rag_chain.invoke(\"How does Spanner increase availability with chaos testing?\")\n",
    "#ai_response = wrapped_text = textwrap.fill(ai_response, width=80)\n",
    "\n",
    "print(ai_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87764aa8",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You can see that there's a meaningful difference in the level of detail and self-consistency between the two approaches. We invite you to play with the various [chunking approaches](https://python.langchain.com/docs/concepts/text_splitters/) to determine the best fit for your use case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1a0e9b",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a13a69",
   "metadata": {},
   "source": [
    "If you created a Spanner instance just to run this demo - to ensure that you don't continue to get billed for the resources you provisioned, just go into the [Cloud Spanner section](https://console.cloud.google.com/spanner/instances/) of the Cloud Console and delete the instance you created."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-spanner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
